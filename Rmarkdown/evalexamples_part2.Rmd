---
title: "EvalExamples"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
library(lubridate)
```

Some examples of model evaluation using results
from a hydrologic model applied to a Sierra watershed

We will also learn a bit more about dealing with dates in R

**lubridate** has some useful functions

```{r simple}

sager = read.table("../Data/sager.txt", header=T)
head(sager)

# add date from the existing columns of day, month, year
sager = sager %>% mutate(date=make_date(year=year, month=month, day=day))

# plot
sagerl = sager %>% gather(key="source",value="streamflow",-date,-month,-day,-wy,-wyd,-year)

# basic plot to look at how well streamflow is tracked through time
# seasonality, changes through years..
ggplot(sagerl, aes(date, streamflow, col=source, linetype=source))+geom_line()

# change access to get a closer look at performance at low values
ggplot(sagerl, aes(date, streamflow, col=source, linetype=source))+geom_line()+scale_y_continuous(trans="log")+labs(y="streamflow mm/day")

# look at it another way - use original data set here
# this tells you about biases but not seasonality or trends through time
ggplot(sager, aes(obs, model))+geom_point()+geom_abline(intercept=0, slope=1, col="red")

# apply some functions to measure performance

source("../R/nse.R")
source("../R/relerr.R")
source("../R/cper.R")
nse(m=sager$model, o=sager$obs)

relerr(m=sager$model, o=sager$obs)*100

cper(m=sager$model, o=sager$obs, weight.nse=0.8)


# try a different time step
sager_wy = sager %>% group_by(wy) %>% summarize(model=sum(model), obs=sum(obs))

nse(sager_wy$model, sager_wy$obs)
cper(m=sager_wy$model, o=sager_wy$obs, weight.nse=0.8)


# just look at august flow
# first sum by month
tmp = sager %>% group_by(month, year) %>% summarize(model=sum(model), obs=sum(obs))
# now extract august
sager_aug = subset(tmp, month==8)
cor(sager_aug$model, sager_aug$obs)

# turn your evaluation metric into a function
source("../R/compute_lowflowmetrics.R")
compute_lowflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy)



# try another metric
```

Peformance evaluation  may depend on what parameter set you use

Calibration is picking parameter sets based on performance evaluation

Apply metrics over multiple outputs (generated by running across many parameters sets) - like we've done in our sensitivity analysis work


```{r multipel}
# multiple results - lets say we've run the model for multiple years, each column
# is streamflow for a different parameter set
msage = read.table("../Data/sagerm.txt", header=T)

# lets say we know the start date from our earlier output
msage$date = sager$date
head(msage)
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy

# and we still have observed data from above
# useful to combine by date to make sure that streamflow and observe match

msage$obs = sager$obs


# how can we plot all results
# to turn all the columns of different outputs into a single column identified by "run"
msagel = msage %>% gather(key="run",value="streamflow", -date, -month, -day, -year, -wy, -obs)

#lets plot water year 1970 otherwise its hard to see
p1=ggplot(subset(msagel, wy == 1970), aes(as.Date(date), streamflow, col=run))+geom_line()+theme(legend.position = "none")
p1
# lets add observed streamflow
p1+geom_line(aes(as.Date(date), obs), size=2, col="black", linetype=2)+labs(y="Streamflow", x="Date")


# compute performance measures for all output
res = msage %>% select(-date, -month, -day, -year, -wy ) %>% map_dbl(~nse(m=.x, o=msage$obs))
summary(res)

# one of them has a "perfect score" why?
# redo
res = msage %>% select(-date, -month, -day, -year, -wy, -obs) %>% map_dbl(~nse(m=.x, o=msage$obs))
summary(res)

# if we want to keep track of which statistics is associated with each run, we need a unique identifies
# a ID that tracks each model output - lets use the column names
simnames = names(msage %>% select(-date, -month, -day,-year,-wy, -obs))
results = cbind.data.frame(simnames=simnames, nse=res)

# another example using our low flow statistics
# use apply to compute for all the data
res = msage %>% select(-date, -month, -day, -year, -wy, -obs ) %>% map(~compute_lowflowmetrics( o=msage$obs, month=msage$month, day=msage$day, year=msage$year, wy=msage$wy, m=.x))

# extract 
  map(res,"[",c("low_month_cor","low_month_err","annual_min_cor","annual_min_err")) %>% map("[",c("low_month_cor","low_month_err","annual_min_cor","annual_min_err"))

# extract information from the list
results = as.data.frame(matrix(unlist(res), byrow=T, ncol=4))
colnames(results)=c("annual_min_err","annual_min_cor", "low_month_err",
              "low_month_cor")

# interesting to look at range of metrics - could use this to decide on
# acceptable values
summary(results)

# graph range of performance measures
resultsl = results %>% gather(key="metric",value="value")
ggplot(resultsl, aes(metric, value))+geom_boxplot()+facet_wrap(~metric, scales="free")

# try this
# assign an identifier to each row, use the same identify for columns of original streamflow data
# we can then use that to pick data
results$setid = seq(from=1,to=nrow(results))

head(msage)
colnames(msage)=c(results$setid, "date","month","year","day","wy")
msagel = msage %>% gather(key="setid",value="streamflow", -date, -month, -year, -day, -wy)

# pick only good parameters
# use absolute value (abs) for the error as you want it to be small magnitdue, whether +ve or -ve
accept_par = subset(results, annual_min_cor > 0.7 & low_month_cor > 0.7 & abs(annual_min_err < 0.2) & abs(low_month_err) < 5)
nrow(accept_par)

# here are some possible ways to plot
# plot only these streamflow
# plot all streamflow but color code by whether its acceptable
msagel$accept = ifelse(msagel$setid %in% accept_par$setid, TRUE, FALSE)
ggplot(msagel, aes(as.Date(date), streamflow, col=accept))+geom_line()

# shorter period for better visualizaton
ggplot(subset(msagel, wy==1970), aes(as.Date(date), streamflow, col=accept))+geom_line()

# focus only on annual minimum flow

annual_min_all = msagel %>% group_by(setid, wy) %>% summarize(minstr=min(streamflow), 
                                                              minstro=min(obs))

# tag (as TRUE) all the acceptable (post calibration values)
annual_min_all$accept = ifelse(annual_min_all$setid %in% accept_par$setid, TRUE, FALSE)
                                                             

ggplot(annual_min_all, aes(x="", y=minstr, fill=accept))+geom_boxplot()
                                                                          
       
       
```

Picking only the 'best' parameter set - not ideal as there is parameter uncertainty
because of uncertainty in which metric to use, and which output

```{r best}

summary(results)

# lets pick the one where the multiplication of low_month and annual min correlations is the highest (weights them both equally)

results$combined = results$annual_min_cor * results$low_month_cor

# find the parameter set that has the highest value
best_par_setid = results$setid[which.max(results$combined)]

# select that streamflow and then plot
# use log y axis because we are interested in low flows
msagel$best = ifelse(msagel$setid == best_par_setid, TRUE, FALSE)
ggplot(subset(msagel, wy < 1970), aes(as.Date(date), streamflow, col=best))+
  geom_line() +
 geom_line(aes(as.Date(date), obs), col="cyan")+scale_y_continuous(trans="log")

# check how mean of annual minimum flow changes with calibration
annual_min_all$best = ifelse(annual_min_all$setid == best_par_setid, TRUE, FALSE)

annual_min_all %>% group_by(best) %>% summarize(mean=mean(minstr), meano=mean(minstro)) 
                                                             
